[pandas]
구조화된데이터의처리를지원하는Python 라이브러리 Python계의엑셀!
-구조화된데이터의처리를지원하는Python 라이브러리
-고성능Array 계산라이브러리인Numpy와통합하여, 강력한“스프레드시트” 처리기능을제공
-인덱싱, 연산용함수, 전처리함수등을제공함

[데이터로딩]
>>> import pandas as pd
# Data URL
>>> data_url='https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'
# csv타입 데이터 로드, separate는 빈공간으로 지정하고, column은 없음
>>> df_data=pd.read_csv(data_url, sep='\s+',header=None)
>>> df_data.head()  # 처음 다섯줄 출력
        0     1     2   3      4   ...      9     10      11    12    13
0  0.00632  18.0  2.31   0  0.538  ...   296.0  15.3  396.90  4.98  24.0
1  0.02731   0.0  7.07   0  0.469  ...   242.0  17.8  396.90  9.14  21.6
2  0.02729   0.0  7.07   0  0.469  ...   242.0  17.8  392.83  4.03  34.7
3  0.03237   0.0  2.18   0  0.458  ...   222.0  18.7  394.63  2.94  33.4
4  0.06905   0.0  2.18   0  0.458  ...   222.0  18.7  396.90  5.33  36.2

[5 rows x 14 columns]
>>>

[Pandas의 구성]
Series
 - DataFrame 중 하나의 Column에 해당하는 데이터의 모음 Object
DataFrame
 - Data Table 전체를 포함하는Object

>>> from pandas import Series,DataFrame
>>> import pandas as pd
>>> list_data=[1,2,3,4,5]
>>> example_obj=Series(data=list_data)
>>> example_obj
0    1
1    2
2    3
3    4
4    5
dtype: int64


>>> list_name=['a','b','c','d','e']
>>> example_obj=Series(data=list_data,index=list_name)
>>> example_obj
a    1
b    2
c    3
d    4
e    5
dtype: int64
>>>

>>> import numpy as np
>>> dict_data={'a':1,'b':2,'c':3,'d':4,'e':5}
>>> example_obj=Series(dict_data, dtype=np.float32, name='example_data')
>>> example_obj
a    1.0
b    2.0
c    3.0
d    4.0
e    5.0
Name: example_data, dtype: float32
>>>
>>> example_obj['a']  #data index에접근하기
1.0
>>> example_obj['a']=3.2 #data index에값할당하기
>>> example_obj
a    3.2
b    2.0
c    3.0
d    4.0
e    5.0
Name: example_data, dtype: float32
>>>

>>> example_obj.values
array([3.2, 2. , 3. , 4. , 5. ], dtype=float32)
>>> example_obj.index
Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

>>> example_obj.name='number'
>>> example_obj.index.name="alphabet"
>>> example_obj

alphabet
a    3.2
b    2.0
c    3.0
d    4.0
e    5.0
Name: number, dtype: float32
>>>

[Dataframe Overview]
>>>raw_data={'first_name':['Jason','Molly','Tina','Jake','Amy'],
'last_name':['Miller','Jacobson','Ali','Milner','Cooze'],
'age' :[42,52,36,24,73],'city':['San Francisco','Baltimore','Miami','Douglas','Bostone']}
>>> df=pd.DataFrame(raw_data,columns=['first_name','last_name','age','city'])
>>> df
  first_name last_name  age           city
0      Jason    Miller   42  San Francisco
1      Molly  Jacobson   52      Baltimore
2       Tina       Ali   36          Miami
3       Jake    Milner   24        Douglas
4       Amy     Cooze   73        Bostone
>>>

>>> DataFrame(raw_data, columns=['age','city'])  #column 선택
   age           city
0   42  San Francisco
1   52      Baltimore
2   36          Miami
3   24        Douglas
4   73        Bostone
>>>
>>> df=DataFrame(raw_data, columns=['first_name','last_name','age','city','debt'])
  first_name last_name  age           city debt
0      Jason    Miller   42  San Francisco  NaN
1      Molly  Jacobson   52      Baltimore  NaN
2       Tina       Ali   36          Miami  NaN
3       Jake    Milner   24        Douglas  NaN
4        Amy     Cooze   73        Bostone  NaN
>>>


>>> df.first_name   #column 선택 – series 추출
0    Jason
1    Molly
2     Tina
3     Jake
4      Amy
Name: first_name, dtype: object

>>> df['first_name'] #column 선택 – series 추출
0    Jason
1    Molly
2     Tina
3     Jake
4      Amy
Name: first_name, dtype: object
>>>

>>> df.loc[1]
first_name        Molly
last_name      Jacobson
age                  52
city          Baltimore
Name: 1, dtype: object
>>>

>>> df['age'].iloc[1:]
1    52
2    36
3    24
4    73
Name: age, dtype: int64
>>>

>>> s=pd.Series(np.nan, index=[49,48,47,46,45,1,2,3,4,5])
>>> s
49   NaN
48   NaN
47   NaN
46   NaN
45   NaN
1    NaN
2    NaN
3    NaN
4    NaN
5    NaN
dtype: float64

>>> s.loc[:3]  #loc은 index 이름
49   NaN
48   NaN
47   NaN
46   NaN
45   NaN
1    NaN
2    NaN
3    NaN
dtype: float64

>>> s.iloc[:3] #iloc은 index number
49   NaN
48   NaN
47   NaN
dtype: float64
>>>

>>> df=DataFrame(raw_data, columns=['first_name','last_name','age','city','debt'])
>>> df.debt = df.age > 40
>>> df
  first_name last_name  age           city   debt
0      Jason    Miller   42  San Francisco   True
1      Molly  Jacobson   52      Baltimore   True
2       Tina       Ali   36          Miami  False
3       Jake    Milner   24        Douglas  False
4        Amy     Cooze   73        Bostone   True
>>>

>>> df.T
                        0          1      2        3        4
first_name          Jason      Molly   Tina     Jake      Amy
last_name          Miller   Jacobson    Ali   Milner    Cooze
age                    42         52     36       24       73
city        San Francisco  Baltimore  Miami  Douglas  Bostone
debt                 True       True  False    False     True
>>> df.values
array([['Jason', 'Miller', 42, 'San Francisco', True],
       ['Molly', 'Jacobson', 52, 'Baltimore', True],
       ['Tina', 'Ali', 36, 'Miami', False],
       ['Jake', 'Milner', 24, 'Douglas', False],
       ['Amy', 'Cooze', 73, 'Bostone', True]], dtype=object)
>>> df.to_csv()
',first_name,last_name,age,city,debt\n0,Jason,Miller,42,San Francisco,True\n1,Molly,Jacobson,52,Baltimore,True\n2,Tina,Ali,36,Miami,False\n3,Jake,Milner,24,Douglas,False\n4,Amy,Cooze,73,Bostone,True\n'
>>>

>>> del df['debt']
>>> df
  first_name last_name  age           city
0      Jason    Miller   42  San Francisco
1      Molly  Jacobson   52      Baltimore
2       Tina       Ali   36          Miami
3       Jake    Milner   24        Douglas
4        Amy     Cooze   73        Bostone
>>>

>>> pop={'Nevada' :{2001:2.4, 2002:2.9},'Ohio':{2000:1.5,2001:1.7, 2002:3.6}}
>>> DataFrame(pop)
      Nevada  Ohio
2000     NaN   1.5
2001     2.4   1.7
2002     2.9   3.6

>>> import xlrd  # xlrd module 설치
>>> df = pd.read_excel("C://data.xlsx")
>>>
>>> df.head()
   account                         name  ...       Feb    Mar
0   211829   Kerluke, Koepp and Hilpert  ...     62000  35000
1   320563               Walter-Trantow  ...     45000  35000
2   648336   Bashirian, Kunde and Price  ...    120000  35000
3   109996  D'Amore, Gleichner and Bode  ...    120000  10000
4   121213                Bauch-Goldner  ...    120000  35000

[5 rows x 9 columns]

[Selection	&	Drop]
- Selection with column names

>>> df['account'].head(3) #한개의 column 선택시
0    211829
1    320563
2    648336
Name: account, dtype: int64

>>> df[['account','street','state']].head(3) #1개 이상의 column 선택
   account                                street          state
0   211829                    34456 Sean Highway          Texas
1   320563                     1311 Alvis Tunnel  NorthCarolina
2   648336  62184 Schamberger Underpass Apt. 231           Iowa

- Selection with index number

>>> df[:3]  #column 이름 없이 사용하는 index number는 row 기준 표시
   account                        name  ...       Feb    Mar
0   211829  Kerluke, Koepp and Hilpert  ...     62000  35000
1   320563              Walter-Trantow  ...     45000  35000
2   648336  Bashirian, Kunde and Price  ...    120000  35000

[3 rows x 9 columns]

>>> df['account'][:3] #column이름과 함께 row index 사용시, 해당 column만
0    211829
1    320563
2    648336
Name: account, dtype: int64

- Series selection

>>> account_serires=df['account']
>>> account_serires[:3]
0    211829
1    320563
2    648336
Name: account, dtype: int64

>>> account_serires[[0,1,2]] #1개 이상의 index
0    211829
1    320563
2    648336
Name: account, dtype: int64

>>> account_serires[account_serires<250000] #Boolean index
0    211829
3    109996
4    121213
Name: account, dtype: int64
>>>

- Index 변경
>>> df.index=df['account']
>>> df
         account                         name  ...       Feb    Mar
account                                        ...
211829    211829   Kerluke, Koepp and Hilpert  ...     62000  35000
320563    320563               Walter-Trantow  ...     45000  35000
648336    648336   Bashirian, Kunde and Price  ...    120000  35000
109996    109996  D'Amore, Gleichner and Bode  ...    120000  10000
121213    121213                Bauch-Goldner  ...    120000  35000

[5 rows x 9 columns]

>>> del df['account']
>>> df
                                name  ...      Mar
account                               ...
211829    Kerluke, Koepp and Hilpert  ...    35000
320563                Walter-Trantow  ...    35000
648336    Bashirian, Kunde and Price  ...    35000
109996   D'Amore, Gleichner and Bode  ...    10000
121213                 Bauch-Goldner  ...    35000

[5 rows x 8 columns]

- Basic, loc, ilocselection

>>> df[['name','street']][:2] #Column 과 index number
                               name              street
account
211829   Kerluke, Koepp and Hilpert  34456 Sean Highway
320563               Walter-Trantow   1311 Alvis Tunnel
>>>

>>> df.loc[[211829, 320563],['name','street']] #Column 과 index name
                               name              street
account
211829   Kerluke, Koepp and Hilpert  34456 Sean Highway
320563               Walter-Trantow   1311 Alvis Tunnel
>>>

>>> df.iloc[:2, :2]  #Column number와 index number
                               name              street
account
211829   Kerluke, Koepp and Hilpert  34456 Sean Highway
320563               Walter-Trantow   1311 Alvis Tunnel

- index 재설정

>>> df.index=list(range(0,5))
>>> df
                          name  ...      Mar
0   Kerluke, Koepp and Hilpert  ...    35000
1               Walter-Trantow  ...    35000
2   Bashirian, Kunde and Price  ...    35000
3  D'Amore, Gleichner and Bode  ...    10000
4                Bauch-Goldner  ...    35000

[5 rows x 8 columns]
>>>

- Data drop

>>> df.drop(1) #Index number로 drop
                          name  ...      Mar
0   Kerluke, Koepp and Hilpert  ...    35000
2   Bashirian, Kunde and Price  ...    35000
3  D'Amore, Gleichner and Bode  ...    10000
4                Bauch-Goldner  ...    35000

[4 rows x 8 columns]
>>>

>>> df.drop([0,1,2]) #한개 이상의 Index number로 drop
                          name  ...      Mar
3  D'Amore, Gleichner and Bode  ...    10000
4                Bauch-Goldner  ...    35000

[2 rows x 8 columns]
>>>

>>> df.drop([0,1,2], inplace=True)
>>> df
                          name  ...      Mar
3  D'Amore, Gleichner and Bode  ...    10000
4                Bauch-Goldner  ...    35000

[2 rows x 8 columns]

>>> df.drop('name', axis=1) #axis 지정으로 축을 기준으로 drop -> column 중에 “name”
                        street             city  ...       Feb    Mar
3  155 Fadel Crescent Apt. 144       Hyattburgh  ...    120000  10000
4          7274 Marissa Common  Shanahanchester  ...    120000  35000

[2 rows x 7 columns]
>>>

>>> df
                          name  ...      Mar
3  D'Amore, Gleichner and Bode  ...    10000
4                Bauch-Goldner  ...    35000

[2 rows x 8 columns]
>>>

>>> df.drop('name', inplace=True, axis=1)

[ Dataframe Operations ]

- Series operation

>>> s1=Series(range(1,6), index=list('abced'))
>>> s1
a    1
b    2
c    3
e    4
d    5
dtype: int64
>>>

>>> s2=Series(range(5,11), index=list('bcedef'))
>>> s2
b     5
c     6
e     7
d     8
e     9
f    10
dtype: int64
>>>

>>> s1.add(s2)
a     NaN
b     7.0
c     9.0
d    13.0
e    11.0
e    13.0
f     NaN
dtype: float64
>>>

>>> s1+s2 #index 으로 기준으로 연산수행 겹치는 index가 없을 경우 NaN값으로 반환
a     NaN
b     7.0
c     9.0
d    13.0
e    11.0
e    13.0
f     NaN
dtype: float64
>>>

- Dataframe operation

>>> df1=DataFrame(np.arange(9).reshape(3,3), columns=list('abc'))
>>> df1
   a  b  c
0  0  1  2
1  3  4  5
2  6  7  8
>>>

>>> df2=DataFrame(np.arange(16).reshape(4,4), columns=list('abcd'))
>>> df2
    a   b   c   d
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15
>>>

>>> df1+df2
      a     b     c   d
0   0.0   2.0   4.0 NaN
1   7.0   9.0  11.0 NaN
2  14.0  16.0  18.0 NaN
3   NaN   NaN   NaN NaN
>>>

- Operation types: add, sub, div, mul

>>> df1.add(df2, fill_value=0) #df는 column과 index를 모두 고려 add operation을 쓰면 NaN값 0으로 변환
      a     b     c     d
0   0.0   2.0   4.0   3.0
1   7.0   9.0  11.0   7.0
2  14.0  16.0  18.0  11.0
3  12.0  13.0  14.0  15.0
>>>

- Series + Dataframe

>>> df=DataFrame(np.arange(16).reshape(4,4), columns=list('abcd'))
>>> df
    a   b   c   d
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15

>>> s =Series(np.arange(10,14), index=list('abcd'))
>>> s
a    10
b    11
c    12
d    13
dtype: int32
>>>

>>> df + s #column을 기준으로 broadcasting이 발생함
    a   b   c   d
0  10  12  14  16
1  14  16  18  20
2  18  20  22  24
3  22  24  26  28
>>>

>>> df=DataFrame(np.arange(16).reshape(4,4), columns=list('abcd'))
>>> df
    a   b   c   d
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15
>>> s2 =Series(np.arange(10,14))
>>> s2
0    10
1    11
2    12
3    13
dtype: int32

>>> df+s2
    a   b   c   d   0   1   2   3
0 NaN NaN NaN NaN NaN NaN NaN NaN
1 NaN NaN NaN NaN NaN NaN NaN NaN
2 NaN NaN NaN NaN NaN NaN NaN NaN
3 NaN NaN NaN NaN NaN NaN NaN NaN
>>>

>>> df.add(s2, axis=0)  #axis를 기준으로 row broadcasting 실행
    a   b   c   d
0  10  11  12  13
1  15  16  17  18
2  20  21  22  23
3  25  26  27  28
>>>

[lambda, map, apply]

Lambda 함수 - 한 줄로 함수를 표현하는 익명 함수 기법
- Lisp 언어에서 시작된 기법으로 오늘날 현대언어에 많이 사용
  lambda argument : expression

map 함수
- 함수와 sequence형 데이터를 인자로 받아
- 각 element마다 입력받은 함수를 적용하여 list로 반환
- 일반적으로 함수를 lambda형태로 표현함
  map(function, sequence)

map for series
- Pandas의 series type의 데이터에도 map 함수 사용가능
- function 대신 dict, sequence형 자료등으로 대체 가능

>>> s1=Series(np.arange(10))
>>> s1.head(5)
0    0
1    1
2    2
3    3
4    4
dtype: int32

>>> s1.map(lambda x:x**2).head(5)
0     0
1     1
2     4
3     9
4    16
dtype: int64
>>>

>>> z={1:'A', 2:'B', 3:'C'}
>>> s1.map(z).head(5) #dict type으로 데이터 교체 없는 값은 NaN

0    NaN
1      A
2      B
3      C
4    NaN
dtype: object
>>>

>>> s2=Series(np.arange(10,20))
>>> s2.head(5)
0    10
1    11
2    12
3    13
4    14
dtype: int32
>>>

- Example - map for series

>>> url='https://raw.githubusercontent.com/rstudio/Intro/master/data/wages.csv'
>>> df = pd.read_csv(url)
>>> df.head()
           earn  height     sex   race  ed  age
0  79571.299011   73.89    male  white  16   49
1  96396.988643   66.23  female  white  16   62
2  48710.666947   63.77  female  white  16   33
3  80478.096153   63.22  female  other  16   95
4  82089.345498   63.08  female  white  17   43

>>> df.sex.unique()
array(['male', 'female'], dtype=object)
>>> df["sex_code"] =  df.sex.map({"male":0, "female":1}) #성별 str -> 성별 code
>>> df.head(5)
           earn  height     sex   race  ed  age  sex_code
0  79571.299011   73.89    male  white  16   49         0
1  96396.988643   66.23  female  white  16   62         1
2  48710.666947   63.77  female  white  16   33         1
3  80478.096153   63.22  female  other  16   95         1
4  82089.345498   63.08  female  white  17   43         1
>>>

>>> df.sex.replace(['male','female'],[0,1], inplace=True)
>>> df.head()
           earn  height  sex   race  ed  age
0  79571.299011   73.89    0  white  16   49
1  96396.988643   66.23    1  white  16   62
2  48710.666947   63.77    1  white  16   33
3  80478.096153   63.22    1  other  16   95
4  82089.345498   63.08    1  white  17   43
>>>

>>> del df['sex_code']
>>>

[apply for dataframe]
- map과 달리, series 전체(column)에 해당 함수를 적용
- 입력값이 series 데이터로 입력받아 handling 가능

>>> df_info=df[['earn','height','age']]
>>> df_info.head()
           earn  height  age
0  79571.299011   73.89   49
1  96396.988643   66.23   62
2  48710.666947   63.77   33
3  80478.096153   63.22   95
4  82089.345498   63.08   43
>>>

>>> f=lambda x : x.max()-x.min()
>>> df_info.apply(f) #각 column 별로 결과값 반환
earn      318047.708444
height        19.870000
age           73.000000
dtype: float64
>>>

- scalar 값 이외에 series값의 반환도 가능함

>>> def f(x) :
	return Series([x.min(), x.max()], index=['min','max'])

>>> df_info.apply(f)
              earn  height  age
min     -98.580489   57.34   22
max  317949.127955   77.21   95

[GroupbyI]
- SQL groupby 명령어와 같음
- split -> apply -> combine
- 과정을 거쳐 연산함

>>> import pandas as pd
>>> ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',
         'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],
         'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],
         'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],
         'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}
>>> df = pd.DataFrame(ipl_data)
>>> df
      Team  Rank  Year  Points
0   Riders     1  2014     876
1   Riders     2  2015     789
2   Devils     2  2014     863
3   Devils     3  2015     673
4    Kings     3  2014     741
5    kings     4  2015     812
6    Kings     1  2016     756
7    Kings     1  2017     788
8   Riders     2  2016     694
9   Royals     4  2014     701
10  Royals     1  2015     804
11  Riders     2  2017     690
>>>
#묶음의 기준이 되는 컬럼(Team), 적용받는 컬럼(Points), 적용받는 연산(sum)
>>> df.groupby("Team")['Points'].sum() #결과 TEAM을 기준으로 Points을 Sum
Team
Devils    1536
Kings     2285
Riders    3049
Royals    1505
kings      812
Name: Points, dtype: int64
>>>

- 한 개이상의 column을 묶을 수 있음

>>> h_index=df.groupby(['Team','Year'])['Points'].sum()
>>> h_index
Team    Year
Devils  2014    863
        2015    673
Kings   2014    741
        2016    756
        2017    788
Riders  2014    876
        2015    789
        2016    694
        2017    690
Royals  2014    701
        2015    804
kings   2015    812
Name: Points, dtype: int64
>>>

[Hierarchical index]
- Groupby 명령의 결과물도 결국은 dataframe
- 두 개의 column으로 groupby를 할 경우, index가 두개 생성

>>> h_index["Devils" : "Kings"]
Team    Year
Devils  2014    863
        2015    673
Kings   2014    741
        2016    756
        2017    788
Name: Points, dtype: int64

[Hierarchical index – unstack()]
- Group으로 묶여진 데이터를 matrix 형태로 전환해줌

>>> h_index.unstack()
Year     2014   2015   2016   2017
Team
Devils  863.0  673.0    NaN    NaN
Kings   741.0    NaN  756.0  788.0
Riders  876.0  789.0  694.0  690.0
Royals  701.0  804.0    NaN    NaN
kings     NaN  812.0    NaN    NaN
>>>

- Index level을 변경할 수 있음

>>> h_index.swaplevel()
Year  Team
2014  Devils    863
2015  Devils    673
2014  Kings     741
2016  Kings     756
2017  Kings     788
2014  Riders    876
2015  Riders    789
2016  Riders    694
2017  Riders    690
2014  Royals    701
2015  Royals    804
      kings     812
Name: Points, dtype: int64
>>>

>>> h_index.swaplevel().sort_index(level=0)
Year  Team
2014  Devils    863
      Kings     741
      Riders    876
      Royals    701
2015  Devils    673
      Riders    789
      Royals    804
      kings     812
2016  Kings     756
      Riders    694
2017  Kings     788
      Riders    690
Name: Points, dtype: int64
>>>

[ Hierarchical index ]
– operations
- Index level을 기준으로 기본 연산 수행 가능

>>> h_index.sum(level=0)
Team
Devils    1536
Kings     2285
Riders    3049
Royals    1505
kings      812
Name: Points, dtype: int64

>>> h_index.sum(level=1)
Year
2014    3181
2015    3078
2016    1450
2017    1478
Name: Points, dtype: int64
>>>

[Groupby - grouped]
-Groupby에 의해 Split된 상태를 추출 가능함

>>> grouped=df.groupby("Team")
>>> for name, group in grouped : # Tuple형태로 그룹의 key값 Value값이 추출됨
	print(name)
	print(group)

Devils
     Team  Rank  Year  Points
2  Devils     2  2014     863
3  Devils     3  2015     673
Kings
    Team  Rank  Year  Points
4  Kings     3  2014     741
6  Kings     1  2016     756
7  Kings     1  2017     788

- 특정 key값을 가진 그룹의 정보만 추출 가능

>>> grouped.get_group('Devils')
     Team  Rank  Year  Points
2  Devils     2  2014     863
3  Devils     3  2015     673
>>>

[ Groupby - grouped]
- 추출된 group정보에는 세가지 유형의 apply가 가능하다.
- Aggregation : 요약된 통계정보를 추출해 줌
- Transformation : 해당 정보를 변환해줌
- Filteration : 특정정보를 제거 하여 보여주는 필터링 기능

[ Groupby : aggregation ]

>>> grouped.agg(sum)
        Rank  Year  Points
Team
Devils     5  4029    1536
Kings      5  6047    2285
Riders     7  8062    3049
Royals     5  4029    1505
kings      4  2015     812

>>> import numpy as np
>>> grouped.agg(np.mean)
            Rank         Year      Points
Team
Devils  2.500000  2014.500000  768.000000
Kings   1.666667  2015.666667  761.666667
Riders  1.750000  2015.500000  762.250000
Royals  2.500000  2014.500000  752.500000
kings   4.000000  2015.000000  812.000000
>>>

- 특정 컬럼에 여러개의 function을 Apply할 수도 있음

>>> grouped['Points'].agg([np.sum, np.mean, np.std])
         sum        mean         std
Team
Devils  1536  768.000000  134.350288
Kings   2285  761.666667   24.006943
Riders  3049  762.250000   88.567771
Royals  1505  752.500000   72.831998
kings    812  812.000000         NaN
>>>


[ Groupby - filter ]
- 특정 조건으로 데이터를 검색할때 사용
- filter안에는 boolean 조건이 존재해야함
- len(x)는 grouped된 Dataframe 개수

>>> df.groupby('Team').filter(lambda x : len(x) >=3)
      Team  Rank  Year  Points
0   Riders     1  2014     876
1   Riders     2  2015     789
4    Kings     3  2014     741
6    Kings     1  2016     756
7    Kings     1  2017     788
8   Riders     2  2016     694
11  Riders     2  2017     690

>>> df.groupby('Team').filter(lambda x : x['Rank'].sum()>2)
      Team  Rank  Year  Points
0   Riders     1  2014     876
1   Riders     2  2015     789
2   Devils     2  2014     863
3   Devils     3  2015     673
4    Kings     3  2014     741
5    kings     4  2015     812
6    Kings     1  2016     756
7    Kings     1  2017     788
8   Riders     2  2016     694
9   Royals     4  2014     701
10  Royals     1  2015     804
11  Riders     2  2017     690

>>> df.groupby('Team').filter(lambda x : x['Points'].max()>800)
      Team  Rank  Year  Points
0   Riders     1  2014     876
1   Riders     2  2015     789
2   Devils     2  2014     863
3   Devils     3  2015     673
5    kings     4  2015     812
8   Riders     2  2016     694
9   Royals     4  2014     701
10  Royals     1  2015     804
11  Riders     2  2017     690
>>>

>>> df.groupby('Team').filter(lambda x : x['Rank'].mean()>1)
      Team  Rank  Year  Points
0   Riders     1  2014     876
1   Riders     2  2015     789
2   Devils     2  2014     863
3   Devils     3  2015     673
4    Kings     3  2014     741
5    kings     4  2015     812
6    Kings     1  2016     756
7    Kings     1  2017     788
8   Riders     2  2016     694
9   Royals     4  2014     701
10  Royals     1  2015     804
11  Riders     2  2017     690
>>>

>>> df_phone=pd.read_csv("C://phone.csv")
>>> df_phone.head()
   index            date  duration     ...         month   network network_type
0      0  15/10/14 06:58    34.429     ...       2014-11      data         data
1      1  15/10/14 06:58    13.000     ...       2014-11  Vodafone       mobile
2      2  15/10/14 14:46    23.000     ...       2014-11    Meteor       mobile
3      3  15/10/14 14:48     4.000     ...       2014-11     Tesco       mobile
4      4  15/10/14 17:27     4.000     ...       2014-11     Tesco       mobile

[5 rows x 7 columns]
>>>

>>> df_phone['date']=df_phone['date'].apply(dateutil.parser.parse, dayfirst=True)
>>> df_phone.head()
   index                date     ...        network network_type
0      0 2014-10-15 06:58:00     ...           data         data
1      1 2014-10-15 06:58:00     ...       Vodafone       mobile
2      2 2014-10-15 14:46:00     ...         Meteor       mobile
3      3 2014-10-15 14:48:00     ...          Tesco       mobile
4      4 2014-10-15 17:27:00     ...          Tesco       mobile

[5 rows x 7 columns]
>>>

>>> df_phone.groupby('month')['duration'].sum()
month
2014-11    26639.441
2014-12    14641.870
2015-01    18223.299
2015-02    15522.299
2015-03    22750.441
Name: duration, dtype: float64
>>>

>>> df_phone[df_phone['item']=='call'].groupby('month')['duration'].sum()
month
2014-11    25547.0
2014-12    13561.0
2015-01    17070.0
2015-02    14416.0
2015-03    21727.0
Name: duration, dtype: float64
>>>

>>> df_phone.groupby(['month','item'])['duration'].sum()
month    item
2014-11  call    25547.000
         data      998.441
         sms        94.000
2014-12  call    13561.000
         data     1032.870
         sms        48.000
2015-01  call    17070.000
         data     1067.299
         sms        86.000
2015-02  call    14416.000
         data     1067.299
         sms        39.000
2015-03  call    21727.000
         data      998.441
         sms        25.000
Name: duration, dtype: float64
>>>

>>> df_phone.groupby('month', as_index=False).agg({'duration': "sum"})
     month   duration
0  2014-11  26639.441
1  2014-12  14641.870
2  2015-01  18223.299
3  2015-02  15522.299
4  2015-03  22750.441
>>>

>>> df_phone.groupby(['month','item']).agg({'duration':sum, 'network_type':'count','date':'first'})
               duration  network_type                date
month   item
2014-11 call  25547.000           107 2014-10-15 06:58:00
        data    998.441            29 2014-10-15 06:58:00
        sms      94.000            94 2014-10-16 22:18:00
2014-12 call  13561.000            79 2014-11-14 17:24:00
        data   1032.870            30 2014-11-13 06:58:00
        sms      48.000            48 2014-11-14 17:28:00
2015-01 call  17070.000            88 2014-12-15 20:03:00
        data   1067.299            31 2014-12-13 06:58:00
        sms      86.000            86 2014-12-15 19:56:00
2015-02 call  14416.000            67 2015-01-15 10:36:00
        data   1067.299            31 2015-01-13 06:58:00
        sms      39.000            39 2015-01-15 12:23:00
2015-03 call  21727.000            47 2015-02-12 20:15:00
        data    998.441            29 2015-02-13 06:58:00
        sms      25.000            25 2015-02-19 18:46:00
>>>

>>> df_phone.groupby(['month','item']).agg({'duration':[min], 'network_type':'count','date':[min,'first', 'nunique']})
             duration network_type   ...              date
                  min        count   ...             first nunique
month   item                         ...
2014-11 call    1.000          107   ...    15/10/14 06:58     104
        data   34.429           29   ...    15/10/14 06:58      29
        sms     1.000           94   ...    16/10/14 22:18      79
2014-12 call    2.000           79   ...    14/11/14 17:24      76
        data   34.429           30   ...    13/11/14 06:58      30
        sms     1.000           48   ...    14/11/14 17:28      41
2015-01 call    2.000           88   ...    15/12/14 20:03      84
        data   34.429           31   ...    13/12/14 06:58      31
        sms     1.000           86   ...    15/12/14 19:56      58
2015-02 call    1.000           67   ...    15/01/15 10:36      67
        data   34.429           31   ...    13/01/15 06:58      31
        sms     1.000           39   ...    15/01/15 12:23      27
2015-03 call    2.000           47   ...    12/02/15 20:15      47
        data   34.429           29   ...    13/02/15 06:58      29
        sms     1.000           25   ...    19/02/15 18:46      17

[15 rows x 5 columns]
>>>

[Merge]
- SQL에서 많이 사용하는 Merge와 같은 기능
- 두 개의 데이터를 하나로 합침
- INNER JOIN, FULL JOIN, LEFT JOIN, RIGHT JOIN

>>> raw_data = {
        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],
        'test_score': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}
>>>
>>> df_a = pd.DataFrame(raw_data, columns = ['subject_id', 'test_score'])
>>> df_a
  subject_id  test_score
0          1          51
1          2          15
2          3          15
3          4          61
4          5          16
5          7          14
6          8          15
7          9           1
8         10          61
9         11          16

>>> raw_data = {
        'subject_id': ['4', '5', '6', '7', '8'],
        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],
        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}
>>> df_b = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])
>>> df_b
  subject_id first_name last_name
0          4      Billy    Bonder
1          5      Brian     Black
2          6       Bran   Balwner
3          7      Bryce     Brice
4          8      Betty    Btisan

>>> pd.merge(df_a, df_b, on='subject_id') #subject_id기준으로 merge
  subject_id  test_score first_name last_name
0          4          61      Billy    Bonder
1          5          16      Brian     Black
2          7          14      Bryce     Brice
3          8          15      Betty    Btisan

>>> pd.merge(df_a, df_b, left_on='subject_id', right_on='subject_id')
  subject_id  test_score first_name last_name
0          4          61      Billy    Bonder
1          5          16      Brian     Black
2          7          14      Bryce     Brice
3          8          15      Betty    Btisan
>>>

>>> pd.merge(df_a, df_b, on='subject_id', how='inner')
  subject_id  test_score first_name last_name
0          4          61      Billy    Bonder
1          5          16      Brian     Black
2          7          14      Bryce     Brice
3          8          15      Betty    Btisan
>>>

[DB]
https://www.dataquest.io/blog/python-pandas-databases/

>>> import pandas as pd

>>> import sqlite3
>>> conn = sqlite3.connect("C://flights.db")
>>> cur = conn.cursor()

>>> cur.execute("select * from airlines limit 5;")

<sqlite3.Cursor object at 0x000002177AD00650>
>>> results = cur.fetchall()

>>> results
[(0, '1', 'Private flight', '\\N', '-', None, None, None, 'Y'), (1, '2', '135 Airways', '\\N', None, 'GNL', 'GENERAL', 'United States', 'N'), (2, '3', '1Time Airline', '\\N', '1T', 'RNX', 'NEXTIME', 'South Africa', 'Y'), (3, '4', '2 Sqn No 1 Elementary Flying Training School', '\\N', None, 'WYT', None, 'United Kingdom', 'N'), (4, '5', '213 Flight Unit', '\\N', None, 'TFU', None, 'Russia', 'N')]
>>> df_airplines = pd.read_sql_query("select * from airlines;", conn)

>>> df_airplines.head()
   index id  ...           country active
0      0  1  ...              None      Y
1      1  2  ...     United States      N
2      2  3  ...      South Africa      Y
3      3  4  ...    United Kingdom      N
4      4  5  ...            Russia      N

[5 rows x 9 columns]
>>>

[matplotlib]
 - pyplot 객체를 사용하여 데이터를 표시
 - Pyplot 객체에 그래프들을 쌓은 다음 show로 flush

 >>> import matplotlib.pyplot as plt

>>> X = range(100)

>>> Y = range(100)

>>> plt.plot(X, Y)
[<matplotlib.lines.Line2D object at 0x000002177F1BB8D0>]
>>> plt.show()
>>>

>>> import matplotlib.pyplot as plt
>>> X = range(100)
>>> Y=[value**2 for value in X]
>>> plt.plot(X, Y)
[<matplotlib.lines.Line2D object at 0x000002177F5090F0>]
>>> plt.show()
>>>

>>> import numpy as np
>>> X_1 = range(100)
>>> Y_1 = [np.cos(value) for value in X]
>>> X_2 = range(100)

>>> Y_2 = [np.sin(value) for value in X]
>>> plt.plot(X_1, Y_1)

[<matplotlib.lines.Line2D object at 0x000002177F1D42E8>]
>>> plt.plot(X_2, Y_2)

[<matplotlib.lines.Line2D object at 0x000002177F1D4E10>]
>>> plt.plot(range(100), range(100))

[<matplotlib.lines.Line2D object at 0x000002177F1F0BA8>]
>>> plt.show()
>>> 